# Known Limitations & Improvement Plan

This document tracks all shortcuts taken during P0 development and what needs to be improved for production.

---

## ğŸš¨ Critical Issues (Blocking P1)

### 1. **Venue Adapters Use Polling, Not Websockets**

**Location**: `src/arbitrage/ingest/polymarket.py:169`, `src/arbitrage/ingest/kalshi.py:161`

**Current Behavior**:
```python
while self._running:
    for market in markets:
        book_data = await self.get_orderbook(token_id)
        # ...
    await asyncio.sleep(2.0)  # âš ï¸ 2 second polling delay
```

**Problem**:
- 2-second polling adds massive latency
- TDD requires p50 â‰¤ 200ms alert-to-order
- Miss fast-moving edges

**Fix Required**:
```python
# Polymarket websocket
async def stream_orderbooks(self):
    async with websockets.connect("wss://clob.polymarket.com") as ws:
        await ws.send(json.dumps({"type": "subscribe", "markets": markets}))
        async for message in ws:
            yield self._parse_orderbook_snapshot(...)

# Kalshi websocket
async def stream_orderbooks(self):
    async with websockets.connect("wss://api.elections.kalshi.com/ws") as ws:
        # Similar implementation
```

**Estimate**: 1-2 days per venue (includes testing)

---

### 2. **LLM Integration Completely Mocked**

**Location**: `src/arbitrage/matching/validators.py:229`

**Current Behavior**:
```python
async def _call_llm(self, prompt: str) -> dict:
    # TODO: Implement actual LLM API calls using httpx
    return {
        "similarity": 0.95,  # âš ï¸ Always returns 0.95
        "explanation": "Markets describe the same event...",
        "field_matches": {...}
    }
```

**Problem**:
- Matching pipeline not validated with real LLM
- Can't achieve TDD requirement: false match rate â‰¤ 0.5%
- No cost tracking for LLM calls

**Fix Required**:
```python
async def _call_llm(self, prompt: str) -> dict:
    if self.provider == "deepseek":
        url = "https://api.deepseek.com/v1/chat/completions"
    else:
        url = "https://api.openai.com/v1/chat/completions"

    async with httpx.AsyncClient() as client:
        response = await client.post(
            url,
            headers={"Authorization": f"Bearer {self.api_key}"},
            json={
                "model": "deepseek-chat" if self.provider == "deepseek" else "gpt-4o",
                "messages": [{"role": "user", "content": prompt}],
                "response_format": {"type": "json_object"}
            }
        )
        return response.json()["choices"][0]["message"]["content"]
```

**Needs**:
- API key management
- Rate limiting (DeepSeek: 60 req/min)
- Retry logic with exponential backoff
- Fallback to GPT-4o on DeepSeek failure
- Cost tracking per LLM call

**Estimate**: 1 day

---

### 3. **Dashboard Uses In-Memory Storage with Fake Data**

**Location**: `src/arbitrage/dashboard/api.py:63`

**Current Behavior**:
```python
# In-memory storage for demo (replace with database queries in production)
_edges: list[EdgeResponse] = []
_fills: list[FillResponse] = []

# Later, generates fake data:
if not _edges:
    _edges.extend([
        EdgeResponse(
            pair_id="pm-0x1234:kalshi-ABC123",
            primary_market="US Election - Trump Yes",  # âš ï¸ Fake
            net_edge_cents=3.2,  # âš ï¸ Fake
            ...
        )
    ])
```

**Problem**:
- Dashboard shows fake demo data
- No real edges/fills displayed
- Can't monitor actual system

**Fix Required**:
```python
from sqlalchemy.ext.asyncio import AsyncSession
from arbitrage.database import get_session
from arbitrage.database.models import Edge, Fill

@app.get("/api/edges")
async def get_edges(
    limit: int = 20,
    session: AsyncSession = Depends(get_session)
):
    stmt = (
        select(Edge)
        .order_by(Edge.net_edge_cents.desc())
        .limit(limit)
    )
    result = await session.execute(stmt)
    edges = result.scalars().all()
    return [EdgeResponse.from_orm(e) for e in edges]
```

**Estimate**: 0.5 days

---

### 4. **Discord Bot Not Connected to Discord**

**Location**: `src/arbitrage/discord_bot/bot.py:169`

**Current Behavior**:
```python
async def send_alert(self, message: str, alert_type: str = "info"):
    # In real implementation, this would use discord.py to send to channel
    # For now, just log
    print(f"[DISCORD ALERT] {formatted}")  # âš ï¸ Just prints
```

**Problem**:
- No actual Discord alerts
- Can't control system remotely
- Commands don't work

**Fix Required**:
```python
import discord
from discord.ext import commands

class ArbitrageBot(commands.Bot):
    def __init__(self, config: BotConfig):
        intents = discord.Intents.default()
        intents.message_content = True
        super().__init__(command_prefix="/", intents=intents)
        self.config = config

    async def send_alert(self, message: str):
        channel = self.get_channel(self.config.channel_id)
        await channel.send(message)

    @commands.command()
    async def edges(self, ctx, limit: int = 5):
        edges = await self._fetch_edges(limit)
        message = self.format_edges_message(edges)
        await ctx.send(message)
```

**Estimate**: 0.5 days

---

## âš ï¸ Important Issues (Needed for Validation)

### 5. **No Historical Data Pipeline**

**Location**: `src/arbitrage/backtest/engine.py:158`

**Current Behavior**:
```python
def run(self, pairs, orderbook_snapshots):
    # orderbook_snapshots parameter is empty - no data to backtest
```

**Problem**:
- Can't validate TDD requirement: Sharpe â‰¥ 2.0
- No way to test matching quality
- Can't measure slippage accuracy

**Fix Required**:
1. Build data fetcher:
```python
class HistoricalDataFetcher:
    async def fetch_polymarket_snapshots(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> list[OrderBookSnapshot]:
        # Fetch from Polymarket historical API
        # Store in Parquet files

    async def fetch_kalshi_snapshots(...):
        # Similar for Kalshi
```

2. Storage format:
```
data/
â”œâ”€â”€ polymarket/
â”‚   â”œâ”€â”€ 2024-01/
â”‚   â”‚   â”œâ”€â”€ market_0x1234_20240101.parquet
â”‚   â”‚   â””â”€â”€ market_0x5678_20240101.parquet
â””â”€â”€ kalshi/
    â””â”€â”€ 2024-01/
        â””â”€â”€ KXELECTION_20240101.parquet
```

3. Replay engine:
```python
class DataReplayer:
    def load_snapshots(self, date_range) -> dict[str, list[OrderBookSnapshot]]:
        # Load from Parquet
        # Align timestamps across venues
        # Return sorted by timestamp
```

**Estimate**: 2-3 days

---

### 6. **Simplified Fee Calculations**

**Location**: `src/arbitrage/signals/friction.py:132`

**Current Behavior**:
```python
# Assume we win, so pay profit fee on the spread
primary_profit_fee = self.poly_calc.calculate_profit_fee(
    size_usd * 0.025  # âš ï¸ Rough 2.5% edge estimate, not actual profit
)
```

**Problem**:
- Profit fees calculated on estimate, not actual P&L
- Doesn't account for tiered fee structures
- Missing maker rebates

**Fix Required**:
```python
def calculate_profit_fee(self, entry_price: float, exit_price: float, size: float) -> float:
    # Calculate actual profit
    if exit_price > entry_price:  # Winning trade
        profit = (exit_price - entry_price) * size
        return profit * self.fees.profit_fee_pct
    return 0.0
```

**Estimate**: 0.5 days

---

## ğŸ“ Minor Issues (Nice to Have)

### 7. **No Websocket Updates in Dashboard**

**Current**: Dashboard polls API every 5 seconds via JavaScript

**Better**: Server-Sent Events (SSE) or WebSocket for real-time updates

```python
@app.get("/api/edges/stream")
async def stream_edges():
    async def event_generator():
        while True:
            edges = await get_latest_edges()
            yield f"data: {json.dumps(edges)}\n\n"
            await asyncio.sleep(1)

    return EventSourceResponse(event_generator())
```

**Estimate**: 1 day

---

### 8. **No Fee Schedule Auto-Update**

**Current**: Hardcoded fee rates

**Better**: Fetch from venue APIs periodically

```python
class FeeScheduleUpdater:
    async def update_polymarket_fees(self):
        # Fetch from Polymarket API
        # Update FeeCalculator rates

    async def run(self):
        while True:
            await self.update_polymarket_fees()
            await self.update_kalshi_fees()
            await asyncio.sleep(3600)  # Update hourly
```

**Estimate**: 0.5 days

---

### 9. **No Authentication on Dashboard**

**Current**: Dashboard is public

**Security Risk**: Anyone can view trades and control system

**Fix**: Add simple auth

```python
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBasic, HTTPBasicCredentials

security = HTTPBasic()

def verify_auth(credentials: HTTPBasicCredentials = Depends(security)):
    if credentials.username != "admin" or credentials.password != "secret":
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED)
    return credentials

@app.get("/api/edges", dependencies=[Depends(verify_auth)])
async def get_edges():
    ...
```

**Estimate**: 0.5 days

---

## ğŸ“Š Summary by Priority

| Issue | Priority | Days | Blocks |
|-------|----------|------|--------|
| Websocket adapters | ğŸ”´ Critical | 3 | P1 Live Trading |
| LLM integration | ğŸ”´ Critical | 1 | Matching Quality |
| Database queries in dashboard | ğŸ”´ Critical | 0.5 | Monitoring |
| Discord.py integration | ğŸŸ¡ Important | 0.5 | Remote Control |
| Historical data pipeline | ğŸŸ¡ Important | 3 | Validation |
| Accurate profit fees | ğŸŸ¡ Important | 0.5 | Edge Accuracy |
| Dashboard websockets | ğŸŸ¢ Nice to have | 1 | UX |
| Fee schedule updater | ğŸŸ¢ Nice to have | 0.5 | Maintenance |
| Dashboard auth | ğŸŸ¢ Nice to have | 0.5 | Security |

**Total Estimate**: 10-12 days to production-ready

---

## âœ… What's Actually Working

Despite the shortcuts, these components are solid:

1. **Database Schema**: Fully implemented with proper indexes
2. **Risk Manager**: Position limits and caps working
3. **Execution State Machine**: No-legging logic correct
4. **Depth Model**: VWAP calculation accurate
5. **Lead-Lag Analyzer**: Cross-correlation math correct
6. **Test Suite**: 30 passing tests with good coverage

The **architecture is sound** - we just need to replace the mocks with real implementations.

---

## ğŸš€ Recommended Implementation Order

### Week 1: Critical Path
1. Day 1: LLM API integration
2. Day 2-3: Websocket adapters (both venues)
3. Day 4: Dashboard database queries
4. Day 5: Discord.py integration

### Week 2: Validation
5. Day 6-8: Historical data pipeline
6. Day 9: Backtest validation (Sharpe â‰¥ 2.0)
7. Day 10: Paper trading preparation

### Week 3+: Production Hardening
- Fee schedule automation
- Dashboard authentication
- Real-time websocket updates
- Monitoring and alerting
- Error recovery

---

## ğŸ§ª Testing Current System

You can test what's working vs fake:

```bash
# Test real components
pytest tests/ingest/test_adapters.py  # Mocked but logic is correct
pytest tests/database/test_models.py  # Real database tests

# Test fake components
python -m arbitrage.dashboard.main  # Shows fake edges/fills
# Bot commands work but don't send to Discord
```

To see the fake data:
```python
from fastapi.testclient import TestClient
from arbitrage.dashboard.api import create_dashboard_app

client = TestClient(create_dashboard_app())
print(client.get("/api/edges").json())  # Fake demo data
```

---

This is a **fully functional P0 prototype** with clear paths to production. The hard parts (architecture, risk logic, matching pipeline, backtest math) are done. We just need to swap mocks for real APIs.
